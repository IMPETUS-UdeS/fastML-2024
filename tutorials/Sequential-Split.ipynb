{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32edca4-4875-42a1-a4b5-818504e2d976",
   "metadata": {},
   "source": [
    "# Sequential Split tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f3f51",
   "metadata": {},
   "source": [
    "### Vivado container bug fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae185577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LD_PRELOAD'] = '/usr/lib/x86_64-linux-gnu/libudev.so.1'\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "#os.environ['LM_LICENSE_FILE'] = 'XXXX@your.xilinx.licence.server' or filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fae0ab",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.15\n",
    "!pip install rule4ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90300e9d",
   "metadata": {},
   "source": [
    "### Controls Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b76d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle if you want to load a saved model or create the example model\n",
    "LOAD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed59406f",
   "metadata": {},
   "source": [
    "## MNIST Example Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff53063",
   "metadata": {},
   "source": [
    "### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Flatten the images and/or resize\n",
    "train_images = np.array([np.array(Image.fromarray(img).resize((28, 28))).flatten() for img in train_images])\n",
    "test_images = np.array([np.array(Image.fromarray(img).resize((28, 28))).flatten() for img in test_images])\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "np.save('X_train_val.npy', train_images)\n",
    "np.save('X_test.npy', test_images)\n",
    "np.save('y_train_val.npy', train_labels)\n",
    "np.save('y_test.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a93656",
   "metadata": {},
   "source": [
    "### Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Create & train model\n",
    "if not LOAD:\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            16,\n",
    "            input_shape=(784,),\n",
    "            name='fc1',\n",
    "            kernel_initializer='lecun_uniform',\n",
    "            kernel_regularizer=l1(0.0001),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(\n",
    "            32,\n",
    "            name='dense',\n",
    "            kernel_initializer='lecun_uniform',\n",
    "            kernel_regularizer=l1(0.0001),\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dense(\n",
    "            10,\n",
    "            name='output',\n",
    "            kernel_initializer='lecun_uniform',\n",
    "            kernel_regularizer=l1(0.0001),\n",
    "        )\n",
    "    )\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(),\n",
    "        loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if labels are integers\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8f27c",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "\n",
    "if LOAD:\n",
    "    model = load_model('your/model/path.h5', custom_objects=co)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f22bb",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438f5e9",
   "metadata": {},
   "source": [
    "### rule4ml function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from rule4ml.models.estimators import MultiModelEstimator\n",
    "def predict_nb_nodes(model_to_predict, hls_config=None, sort=['FPGAs', 'nb_bits'], order=[True, False]):\n",
    "        if hls_config == None:\n",
    "            hls_config = [\n",
    "                {   \n",
    "                    \"model\": {\n",
    "                    \"precision\": precisions,\n",
    "                    \"reuse_factor\": reuse_factors,\n",
    "                    \"strategy\": strategies,\n",
    "                    },\n",
    "                    \"board\": \"pynq-z2\",\n",
    "                }\n",
    "                for reuse_factors, strategies, precisions in itertools.product([1,2,4,8,16,32,64,128,256], \n",
    "                                                         [\"Latency\", \"Resource\"],\n",
    "                                                         [f'ap_fixed<{bit},{bit//2}>' for bit in range(2, 33)])\n",
    "            ]\n",
    "            \n",
    "        # Load default estimator\n",
    "        estimator = MultiModelEstimator()\n",
    "        estimator.load_default_models()\n",
    "        # MultiModelEstimator predictions are formatted as a DataFrame\n",
    "        prediction_df = estimator.predict(model_to_predict, hls_config)\n",
    "    \n",
    "        if not prediction_df.empty:\n",
    "            # Calculate the number of splits needed\n",
    "            prediction_df['FPGAs'] = prediction_df[['DSP (%)', 'FF (%)', 'LUT (%)', 'BRAM (%)']].max(axis=1).apply(lambda x: (x // 100) + 1)\n",
    "            \n",
    "            # Extract nb_bits from the Precision column\n",
    "            prediction_df['nb_bits'] = prediction_df['Precision'].str.extract(r'ap_fixed<(\\d+),')[0].astype(int)\n",
    "            \n",
    "            # Sort by least number of splits, then highest nb_bits\n",
    "            sorted_df = prediction_df.sort_values(by=sort, ascending=order)\n",
    "\n",
    "            strategy, nb_bits, reuse_factor, nb_fpga = sorted_df.iloc[0][['Strategy','nb_bits', 'Reuse Factor', 'FPGAs']]\n",
    "            \n",
    "            return strategy, nb_bits.astype(int), reuse_factor, nb_fpga.astype(int)\n",
    "        return \"No Predictions Found.\", None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa0da6",
   "metadata": {},
   "source": [
    "### Possible Combinations of Split Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862244b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def generate_possible_splits(layers, num_splits):\n",
    "    n = len(layers)\n",
    "    if num_splits >= n or num_splits < 1:\n",
    "        return []\n",
    "\n",
    "    all_splits = []\n",
    "\n",
    "    # Helper function to check if a layer is an activation\n",
    "    def is_activation_layer(layer_name):\n",
    "        activation_layers = ['Activation', 'ReLU', 'Softmax']  # Add more as needed\n",
    "        return any(act_layer.lower() in layer_name.lower() for act_layer in activation_layers)\n",
    "\n",
    "    # Generate splits for the specified number of splits\n",
    "    for indices in combinations(range(1, n), num_splits):\n",
    "        valid_split = True\n",
    "        split = []\n",
    "        prev_index = 0\n",
    "        for index in indices:\n",
    "            if index < n and is_activation_layer(layers[index]) and not is_activation_layer(layers[index - 1]):\n",
    "                valid_split = False\n",
    "                break\n",
    "            split.append(layers[prev_index:index])\n",
    "            prev_index = index\n",
    "        split.append(layers[prev_index:])\n",
    "\n",
    "        if valid_split:\n",
    "            all_splits.append(split)\n",
    "\n",
    "    return all_splits\n",
    "\n",
    "# Example usage\n",
    "# layers = [layer.name for layer in model.layers]\n",
    "# possible_splits = generate_possible_splits(layers, 1)\n",
    "\n",
    "# for split in possible_splits:\n",
    "#     print(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb649f",
   "metadata": {},
   "source": [
    "### Sequential Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb06f9-79d9-4b31-8f4f-0b2a01dd9a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def sequential_splits(model, layer_names):\n",
    "    sub_models = []\n",
    "    for i,names in enumerate(layer_names):\n",
    "        layers = []\n",
    "        for j,name in enumerate(names):\n",
    "            layer = model.get_layer(name)\n",
    "            if i == 0:\n",
    "                layers.append(layer)\n",
    "            elif j == 0:\n",
    "                layers.append(keras.layers.InputLayer(layer.input_shape[1:]))\n",
    "                layers.append(layer)\n",
    "            else:\n",
    "                layers.append(layer)\n",
    "        sub_models.append(keras.Sequential(layers))\n",
    "    return sub_models\n",
    "\n",
    "# Example usage:\n",
    "# possible_sub_models = []\n",
    "# for split in possible_splits:\n",
    "#     possible_sub_models.append(sequential_splits(model, split))\n",
    "\n",
    "# print('number of sub_models ', len(possible_sub_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88299cc",
   "metadata": {},
   "source": [
    "## End to End for Sequential Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083cc9d",
   "metadata": {},
   "source": [
    "### rule4ml Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43519742-daef-4d2e-83d4-dd0a682edeaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequential = False\n",
    "parallel = False\n",
    "\n",
    "# GET SEQUENTIAL SPLITS\n",
    "# Rule4ML estimation\n",
    "strategy, nb_bits, reuse_factor, nb_fpga = predict_nb_nodes(model)\n",
    "\n",
    "if nb_fpga > 1:\n",
    "    sequential = True\n",
    "    print(f'Sequential split needed using the following parameters...')\n",
    "    print(f'Strategy : {strategy}')\n",
    "    print(f'Reuse Factor : {reuse_factor}')\n",
    "    print(f'Precision : ap_fixed<{nb_bits},{nb_bits//2}>')\n",
    "    print(f'Number of nodes: {nb_fpga}')\n",
    "\n",
    "    \n",
    "# GET PARALLEL SPLITS\n",
    "for layer in model.layers:\n",
    "    sub_model = Sequential(layer)\n",
    "    sub_model.build(input_shape=layer.input_shape)\n",
    "    s, b, r, f = predict_nb_nodes(sub_model)\n",
    "    if f > 1:\n",
    "        parallel = True\n",
    "        print(f'Parallel split needed for layerÂ {layer.name} using the following parameters...')\n",
    "        print(f'Strategy : {s}')\n",
    "        print(f'Reuse Factor : {r}')\n",
    "        print(f'Precision : ap_fixed<{b},{b//2}>')\n",
    "        print(f'Number of nodes: {f}')\n",
    "\n",
    "# No split needed\n",
    "if not sequential and not parallel:\n",
    "    print(f'No need for a split using the following parameters...')\n",
    "    print(f'Strategy : {strategy}')\n",
    "    print(f'Reuse Factor : {reuse_factor}')\n",
    "    print(f'Precision : ap_fixed<{nb_bits},{nb_bits//2}>')\n",
    "    print(f'Number of nodes: {nb_fpga}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09458e29",
   "metadata": {},
   "source": [
    "### Generate the Possible Splitted Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348ebbe-7f8b-44a9-a06e-bc3c2f9d67ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the possible splits\n",
    "layers = [layer.name for layer in model.layers]\n",
    "num_splits = nb_fpga.astype(int)-1\n",
    "\n",
    "\n",
    "possible_splits = generate_possible_splits(layers, num_splits)\n",
    "\n",
    "# Split the model according tho the possible splits\n",
    "possible_models = []\n",
    "for split in possible_splits:\n",
    "    possible_models.append(sequential_splits(model, split))\n",
    "\n",
    "# test accuracy before conversion (should be the same as the model)\n",
    "print('Performance of original model before hls4ml...')\n",
    "model.evaluate(np.load('X_test.npy'), np.load('y_test.npy'))\n",
    "y_test = test_labels\n",
    "for i,split_model in enumerate(possible_models):\n",
    "    print(f'Performance of split model #{i} before hls4ml...')\n",
    "    input = test_images\n",
    "    for sub_model in split_model:\n",
    "        output = sub_model.predict(input)\n",
    "        input = output\n",
    "    output = input.argmax(axis=1)\n",
    "    print(f'Accuracy of model #{i} for {len(output)} samples is {(np.sum(output == y_test.argmax(axis=1))/len(output))*100}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9090371f",
   "metadata": {},
   "source": [
    "### HLS Conversion fpr a pynq-z2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to hls4ml\n",
    "# -REMOVE LAST PROJECTs- #\n",
    "# !rm -rf model_split*\n",
    "# --------------------- #\n",
    "import hls4ml\n",
    "\n",
    "# For each possible split combinations do the hls conversions with rule4ml outputs.\n",
    "possible_hls_models = []\n",
    "for j,split_model in enumerate(possible_models):\n",
    "    split_hls_model = []\n",
    "    sub_configs = []\n",
    "    for i,sub_model in enumerate(split_model):\n",
    "        sub_configs.append(hls4ml.utils.config_from_keras_model(sub_model, granularity='model'))\n",
    "        sub_configs[i]['Model']['Strategy'] = strategy\n",
    "        sub_configs[i]['Model']['Precision'] = f'ap_fixed<{nb_bits},{nb_bits//2}>'\n",
    "        sub_configs[i]['Model']['ReuseFactor'] = reuse_factor\n",
    "        split_hls_model.append(hls4ml.converters.convert_from_keras_model(sub_model, \n",
    "                                                                         hls_config=sub_configs[i],\n",
    "                                                                         output_dir=f'model_split_{j}/sub_model_{i}',\n",
    "                                                                         backend='VivadoAccelerator',\n",
    "                                                                         board='pynq-z2',\n",
    "                                                                         part='xc7z020clg400-1'\n",
    "                                                                         ))\n",
    "        split_hls_model[i].compile()\n",
    "    possible_hls_models.append(split_hls_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c6653",
   "metadata": {},
   "source": [
    "### Test the accuracy of the models with the HLS conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6865845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy of the hls models  \n",
    "y_test = test_labels\n",
    "for i,split_hls_model in enumerate(possible_hls_models):\n",
    "    print(f'Performance of split model #{i} after hls4ml...')\n",
    "    input = np.ascontiguousarray(test_images)\n",
    "    for sub_hls_model in split_hls_model:\n",
    "        output = sub_hls_model.predict(input)\n",
    "        input = output\n",
    "    output = input.argmax(axis=1)\n",
    "    print(f'Accuracy of model #{i} for {len(output)} samples is {(np.sum(output == y_test.argmax(axis=1))/len(output))*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e244004",
   "metadata": {},
   "source": [
    "### Bonus build the bitstream in parallel for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cb08a-aec5-4caf-9838-f96457e9cb36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select 1 model default is first\n",
    "sub_hls_models = possible_hls_models[0]\n",
    "\n",
    "# BUILD\n",
    "# Function to call multiple vivado builds\n",
    "def build(i_build):\n",
    "        sub_hls_models[i_build].build(csim=False, export=True, bitfile=True)\n",
    "\n",
    "# Code that parallelize the process\n",
    "import multiprocessing\n",
    "with multiprocessing.Pool() as pool:\n",
    "    print(f'PIDs of worker processes: {[p.pid for p in multiprocessing.active_children()]}')\n",
    "    pool.map(build, range(0, len(sub_hls_models)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "4be45546577efffbeff6b841617f159c5d3aceed70e5e111773a23765fa7450f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
